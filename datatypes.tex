\chapter{Types of data in ecosystems}
\chapterauthor{Barbara}

%0123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789
FLOSS ecosystems produce big data of different types coming from various sources of information like development artefacts or  
operations logs. Such data is useful to describe the ecosystem that produced it and the environment in which it runs by, for example, 
modelling the reliability of the ecosystem's components with defect data.
Unfortunately, the information such data carries may often be incomplete and sometimes totally missing. One of the major  reasons is that 
some types of data are actually unobservable or unaccessible (e.g., data from chats or proprietary sources). 
On the other hand,  partial data coming from a single entity can be potentially augmented by
observing a phenomenon across the whole ecosystem. For example, the activity of a developer on a single FLOSS project can
 be measured with more accuracy by observing the entire ecosystem the original project belongs to: developers might not have 
 contributed to a project since they have worked  in other 
projects of the same ecosystem. Thus, observing the entire ecosystem gives a better indication of if a person is still active, 
has moved from one project to another, or is inactive \cite{BogdanXXX}. 

\subsection{Sources of data}
Data of FLOSS ecosystems are typically collected from and about the development process. Such data carries information of different 
qualities of the software process and product. Being tidy connected with process and products, the types of relevant data and 
the techniques to obtain them can evolve as new practices, technologies or development needs arise. For example, on-line controlled 
experiments via A/B testing  have been recently integrated in the development method ``continuous software delivery" (i.e., the ability 
to incorporate seamlessly changes into production) as decision making instrument for fast delivering of high quality products. 
On the other hand, process and product data can also help produce tools or support new methods of development. For example, data 
stored in code repositories, can be exploited to build recommender systems for developers (e.g., \cite{VillaroelEtAl2016}).  
Usage and operations' data can produce added value in modern development processes as well.  For example, for the method ``DevOps" 
- a recently-born development paradigm that aims at fostering the integration between software development and operations 
- systems and use logs can be exploited to provide feedback in the development process (e.g., again as recommenders).
Worth noticing that such development paradigm not only facilitates the communication between development and operations that
traditionally are kept separated, but it also produces new data types by combining existing data (e.g., log events and source code data
 \cite{MeiNagappanPhDThesis}). Operations data are anyway still not easily accessible as they concern the internal processes of organisations.  
Another promising new sources of data can potentially come from new distributed contexts like the ones compliant with Industry 4.0
standards, where software / system data can be complemented with data coming form sensors and actuators in cloud or edge networks.   

With all this abundance of data and data types, how far can we go? By now, two new questions become impelling: What recommendations can we give to  ecosystems like GitHub to collect such new data? How can we infer and integrate automatically qualitative data?

