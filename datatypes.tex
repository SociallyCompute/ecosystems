\chapter{Types of data in ecosystems}
\chapterauthor{Barbara}

FLOSS ecosystems produce big data of different types coming from various 
sources such as development artefacts and operations logs. 
Such data can be used to describe properties of the ecosystem that produced 
it and the environment in which it runs by, for example, modelling the reliability 
of the ecosystem's components with defect data. Unfortunately, the information 
such data carries may often be incomplete and sometimes totally missing. 
The one major reason is that some types of data are actually unobservable 
or unaccessible as they are hard to collect or analyse (e.g., data from chats \cite{ZouSong2016}) or 
have specific access constraints (privacy or proprietary rights). On the other hand,  
partial data of a FLOSS ecosystem can be potentially augmented by observing 
a phenomenon and gather data  across the whole ecosystem. For example, 
the activity of a developer on a single FLOSS project can be measured 
with more accuracy by observing the entire ecosystem  the original project 
belongs to: developers might not have contributed  to a project since they have 
worked  in other projects of the same ecosystem. 
Thus, observing the entire ecosystem gives a better indication of if a person 
is still active, has moved from one project to another, or is  inactive \cite{BogdanXXX}. 
Thus, what are the major sources of data generated by today FLOSS ecosystems?

\section{Sources of data}
Data of FLOSS ecosystems are typically collected from and about 
the development process. Such data carries information of different 
qualities of the software process and product. Being tidy connected 
with process and products, the types of relevant data and the techniques 
to obtain them  evolve as new practices, technologies or development 
needs appear. For example, on-line controlled experiments via A/B testing  
have been recently integrated in the development for``continuous software delivery" 
- the ability to incorporate seamlessly  changes into production - 
as decision making instrument for fast delivering of high quality products \cite{KevicEtAl2017}. 
On the other hand, process and product data can also help produce tools or 
support new methods of development. 
For example, data stored in code repositories, can be exploited 
to build recommender systems for developers (e.g., \cite{VillaroelEtAl2016}).  
Usage and operations' data can produce added value in modern 
development processes as well.  For example,  in ``DevOps" 
- a recently-born development paradigm that aims at fostering 
the integration between software development and operations 
- systems and use logs can be exploited to provide feedback for the 
development process (e.g., again as recommenders).
Worth noticing that such development paradigm not only facilitates 
the communication between development and operations that
traditionally are kept separated, but it also produces new data types 
by combining existing data (e.g., log events and source code data
 \cite{MeiNagappanPhDThesis}). Operations data are anyway less accessible though 
 as they concern the internal processes of organisations.  
Another promising  sources of data can potentially come from 
new distributed contexts like the ones compliant with Industry 4.0 standards, 
where software / system data can be complemented with data coming 
from sensors and actuators in cloud or edge networks.   

Finally, with all this abundance of data and data types, how far can we go? 
By now, two new questions become impelling: What recommendations 
can we give to  ecosystems like GitHub to collect such new data? 
What is the role of qualitative data and how can we integrate it automatically?

